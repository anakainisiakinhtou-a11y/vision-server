// server.js (FREE VERSION - HuggingFace)
import express from "express";
import cors from "cors";
import fetch from "node-fetch";

const app = express();
app.use(express.json({ limit: "10mb" }));
app.use(cors());

const HF_TOKEN = process.env.HF_TOKEN; // Î”Î©Î¡Î•Î‘Î token Î±Ï€ÏŒ HuggingFace

app.post("/analyze", async (req, res) => {

  // ðŸ”µ Î Î¡ÎŸÎ£Î¤Î•Î˜Î—ÎšÎ• Î‘Î¥Î¤Î— Î— Î“Î¡Î‘ÎœÎœÎ—
  console.log("ðŸ“¸ Î›Î®Ï†Î¸Î·ÎºÎµ Î±Î¯Ï„Î·Î¼Î± Î±Ï€ÏŒ HTML ÏƒÎµÎ»Î¯Î´Î±");

  try {
    const { image } = req.body;
    if (!image) {
      return res.status(400).json({ error: "Î”ÎµÎ½ ÏƒÏ„Î¬Î»Î¸Î·ÎºÎµ ÎµÎ¹ÎºÏŒÎ½Î±." });
    }

    // ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ base64
    const base64 = image.replace(/^data:image\/\w+;base64,/, "");
    const buffer = Buffer.from(base64, "base64");

    // ÎšÎ»Î®ÏƒÎ· ÏƒÏ„Î¿ HuggingFace Vision Model
    const response = await fetch(
      "https://api-inference.huggingface.co/models/nlpconnect/vit-gpt2-image-captioning",
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${HF_TOKEN}`,
          "Content-Type": "application/octet-stream"
        },
        body: buffer
      }
    );

    const result = await response.json();

    let caption = "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î®";

    if (Array.isArray(result) && result[0]?.generated_text) {
      caption = result[0].generated_text;
    }

    res.json({ caption });

  } catch (error) {
    console.error("HF Error:", error);
    res.status(500).json({ error: "Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿Î½ server." });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log("FREE Vision Server running on port " + PORT));
