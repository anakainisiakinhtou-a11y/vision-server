import express from "express";
import cors from "cors";
import fetch from "node-fetch";

const app = express();

app.use(express.json({ limit: "10mb" }));
app.use(cors());

const HF_TOKEN = process.env.HF_TOKEN;

async function queryImage(buffer) {
  const response = await fetch(
    "https://api-inference.huggingface.co/models/nlpconnect/vit-gpt2-image-captioning",
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${HF_TOKEN}`,
        "Content-Type": "application/octet-stream"
      },
      body: buffer
    }
  );

  return await response.json();
}

app.post("/analyze", async (req, res) => {
  console.log("ðŸ“¸ Î›Î®Ï†Î¸Î·ÎºÎµ Î±Î¯Ï„Î·Î¼Î± Î±Ï€ÏŒ HTML");

  try {
    const { image } = req.body;
    if (!image) return res.status(400).json({ error: "No image" });

    const base64 = image.replace(/^data:image\/\w+;base64,/, "");
    const buffer = Buffer.from(base64, "base64");

    let result = await queryImage(buffer);

    if (result.error && result.error.includes("loading")) {
      console.log("â³ Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï†Î¿ÏÏ„ÏŽÎ½ÎµÎ¹... Î¾Î±Î½Î±Î´Î¿ÎºÎ¹Î¼Î® ÏƒÎµ 2s");
      await new Promise(r => setTimeout(r, 2000));
      result = await queryImage(buffer);
    }

    // Î‘Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ caption
    if (Array.isArray(result) && result[0]?.generated_text) {
      return res.json({ caption: result[0].generated_text });
    }

    // Fallback: forced prompt
    return res.json({
      caption: "Î— ÎµÎ¹ÎºÏŒÎ½Î± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿ Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î® ÏƒÎºÎ·Î½Î®, Î±Î»Î»Î¬ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î´ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Î´ÏŽÏƒÎµÎ¹ Î»ÎµÏ€Ï„Î¿Î¼ÎµÏÎ® Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î®."
    });

  } catch (err) {
    console.error("âŒ Î£Ï†Î¬Î»Î¼Î±:", err);
    return res.status(500).json({
      caption: "Î Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î± ÏƒÏ„Î¿Î½ Î´Î¹Î±ÎºÎ¿Î¼Î¹ÏƒÏ„Î®."
    });
  }
});

const PORT = process.env.PORT || 10000;
app.listen(PORT, () => console.log("Vision Server running on port " + PORT));
