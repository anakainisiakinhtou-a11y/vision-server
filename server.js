import express from "express";
import cors from "cors";
import fetch from "node-fetch";

const app = express();

app.use(express.json({ limit: "10mb" }));
app.use(cors());

const HF_TOKEN = process.env.HF_TOKEN;

async function queryImage(buffer) {
  const response = await fetch(
    "https://api-inference.huggingface.co/models/microsoft/git-large-coco",
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${HF_TOKEN}`,
        "Content-Type": "application/octet-stream"
      },
      body: buffer
    }
  );

  return await response.json();
}

app.post("/analyze", async (req, res) => {
  console.log("ðŸ“¸ Î›Î®Ï†Î¸Î·ÎºÎµ Î±Î¯Ï„Î·Î¼Î± Î±Ï€ÏŒ HTML");

  try {
    const { image } = req.body;
    if (!image) return res.status(400).json({ error: "No image" });

    const base64 = image.replace(/^data:image\/\w+;base64,/, "");
    const buffer = Buffer.from(base64, "base64");

    let result = await queryImage(buffer);

    if (result.error && result.error.includes("loading")) {
      console.log("â³ Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï†Î¿ÏÏ„ÏŽÎ½ÎµÎ¹... Î¾Î±Î½Î±Î´Î¿ÎºÎ¹Î¼Î® ÏƒÎµ 2s");
      await new Promise(r => setTimeout(r, 2000));
      result = await queryImage(buffer);
    }

    if (Array.isArray(result) && result[0]?.generated_text) {
      return res.json({ caption: result[0].generated_text });
    }

    console.log("âš  Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ· HF:", result);
    return res.json({ caption: null });

  } catch (err) {
    console.error("âŒ Î£Ï†Î¬Î»Î¼Î±:", err);
    return res.status(500).json({ error: "Server error" });
  }
});

const PORT = process.env.PORT || 10000;
app.listen(PORT, () => console.log("Vision Server running on port " + PORT));
